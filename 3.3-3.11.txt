2018.3.3　周六　大雪

1.github设置：
Adding a new SSH key to your GitHub account：https://help.github.com/articles/adding-a-new-ssh-key-to-your-github-account/
删除项目:进入项目->settings->下拉Delete this repository(http://blog.csdn.net/chenshuyang716/article/details/52586431)

git地址:https://github.com/wenjinghy/Diary.git

添加远程库
关联远程库(git remote add origin https://github.com/wenjinghy/Diary.git)
关联后，使用命令git push -u origin master第一次推送master分支的所有内容
只要本地作了提交，就可以通过命令:git push origin master把本地master分支的最新修改推送至GitHub

2.六麦环形阵列：
模块利用麦克风阵列的空域滤波特性（不仅利用了声音的时间频率特性，还利用了空间特性）,通过对唤醒人的角度定位,形成定向拾音波束,并对波束以外的噪声进行抑制,以保证较高的录音质量。
六个拾音波束，各自对应60°范围　阵列算法通过增强波束范围内的声音，削弱波束外的声音，以增强　录音信噪比；
５ｍ远场拾音，声源定位，多种拾音模式（唤醒、定向、全向），中英文唤醒词，唤醒效果检测（评分、调参）
附：唤醒拾音模式即每次说话前需对麦克风进行唤醒,之后麦克风才可以拾取声源所在方向上的声音;定向拾音模式即开发者可随时指定特定的麦克风进行拾音,使设备达到跟踪声源进行拾音的效果,主要适用于机器人等场景;全向拾音模式即麦克风阵列无需唤醒,可拾取任意方向上声源的声音,可适用于通话、会议等场景

科大讯飞技术文档：硬件连接实物图、SecureCRT工具（命令设置）
声纹识别：是一项提取说话人声音特征和说话内容信息，自动核验说话人身份的技术

3.决策树算法：
决策树：从根节点开始一步步走到子节点（决策）
所有的数据最终都会落到叶子节点，既可以做分类也可以做回归

树的组成:
根节点：第一个选择点
非叶子节点与分支:中间过程
叶子节点：最终的决策结果

增加节点相当于在数据中切一刀

决策树的训练与测试:
训练阶段：从给定的训练集构造出一颗树（从根节点开始选择特征，如何进行特征切分）
测试阶段：根据构造出的树模型从上到下走一遍

如何切分特征（选择节点）:衡量标准－熵 选择信息增益最大的作为根节点，依次
信息增益（特征X使得类Y不确定性减少的程度）问题（ID)增益为０
信息增益率:信息增益/自身熵值（解决ID问题，考虑自身熵)
CART：使用GINI系数当做衡量标准　GINI系数：1-概率平方的累加

熵：随机变量不确定性的度量　公式：H(x)=-累加p*logp

决策树的构造实例：

决策树剪枝策略：
预剪枝（边建立边剪枝，限制深度-特征数、叶子节点个数、信息增益，常用）
后剪枝（叶子节点越多，损失越大）
第５节完

2018.3.4　周日　晴

ubuntu无自带flash插件
ubuntu16.04如何通过Firefox安装Flash插件(https://jingyan.baidu.com/article/2fb0ba40a7832600f2ec5f80.html)

te：Training Epochs，训练迭代次数
tf.truncated_normal()，变量初始化为标准截断正态分布的随机数
tf.zeros()，变量初始化为0　　　　
display_step = 1　每多少次迭代显示一次损失

# tensor `a` is [1.8, 2.2], dtype=tf.float  
tf.cast(a, tf.int32) ==> [1, 2]  # dtype=tf.int32  类型转换函数
duce_mean(x) ==> 2.5 #如果不指定第二个参数，那么就在所有的元素中取平均值
tf.reduce_mean(x, 0) ==> [2.,  3.] #指定第二个参数为0，则第一维的元素取平均值，即每一列求平均值

tensorflow中有一类在tensor的某一维度上求值的函数。如：
求最大值tf.reduce_max(input_tensor, reduction_indices=None, keep_dims=False, name=None)
求平均值tf.reduce_mean(input_tensor, reduction_indices=None, keep_dims=False, name=None)
参数1--input_tensor:待求值的tensor。
参数2--reduction_indices:在哪一维上求解。　参数（3）（4）可忽略
tf.argmax的使用（http://blog.csdn.net/uestc_c2_403/article/details/72232807）

读DeepSpeech＆DeepSpeech２论文（论文、译、笔记 在Documents/DeepSpeech论文中）

2018.3.5 周一　晴

读DeepSpeech＆DeepSpeech２论文（论文、译、笔记 在Documents/DeepSpeech论文中）

softmax函数的特点和作用是什么（https://www.zhihu.com/question/23765351杨思达ok忆臻详解）
元素的softmax值为:该元素的指数，与所有元素指数和的比值 把值映射到0到1上，可认为是概率
loss定义为交叉熵：-㏒(softmax)　概率越大，损失越小
最后结果的形式非常的简单，只要将算出来的概率的向量对应的真正结果的那一维减1，就可以了
科大讯飞的语音听写　研究
晚上高级程序设计课　基本：熟悉的教材　敲代码正比变成能力　交流

2018.3.6　周二　晴

ubuntu 16.04 VSCode 配置C++开发环境 （http://blog.csdn.net/u011258217/article/details/78693564）
ubuntu16.04版本的名称xenial
添加更改源：system settings->software&updates
PPA源（Personal Package Archives 个人软件包文档）
https://www.cnblogs.com/EasonJim/p/7119331.html＆https://imcn.me/ppa

3.6&3.7打标签

2018.3.8　周四　晴

编辑makefile文件：insert->进入编辑模式->esc(退出编辑)->shift:->wq
linux makefile教程（http://blog.csdn.net/liang13664759/article/details/1771246/）
makefile都成为了一种在工程方面的编译方法，关系到了整个工程的编译规则
makefile带来的好处就是——“自动化编译”　无论是C、C++、还是pas，首先要把源文件编译成中间代码文件，在Windows下也就是 .obj 文件，UNIX下是 .o 文件，即 Object File，这个动作叫做编译（compile）。然后再把大量的Object File合成执行文件，这个动作叫作链接（link）　

配置讯飞听写　失败(source 64bit_make.sh报错)
设置当前用户的环境变量：sudo gedit ~/.bashrc 打开.bashrc文件　末尾添加路径（eg:export PATH=/opt/EmbedSky/4.3.3/bin:$PATH 其中/opt/EmbedSky/4.3.3/bin为你自己需要设置的环境变量路径）使其立即生效，在终端执行：source ~/.bashrc
ubuntu16.04配置环境变量（https://www.cnblogs.com/imayi/p/6082122.html＆http://blog.csdn.net/baidu_34045013/article/details/78237825＆http://blog.csdn.net/Bleachswh/article/details/51334661）
Linux下profile和bashrc四种的区别（https://zhidao.baidu.com/question/556207103012196652.html:
全局vs当前用户　.bashrc vs .profile
译完DeepSpeech论文　（论文、译、笔记 在Documents/DeepSpeech论文中）

