2018.3.3　周六　大雪

1.github设置：
Adding a new SSH key to your GitHub account：https://help.github.com/articles/adding-a-new-ssh-key-to-your-github-account/
删除项目:进入项目->settings->下拉Delete this repository(http://blog.csdn.net/chenshuyang716/article/details/52586431)

git地址:https://github.com/wenjinghy/Diary.git

添加远程库
关联远程库(git remote add origin https://github.com/wenjinghy/Diary.git)
关联后，使用命令git push -u origin master第一次推送master分支的所有内容
只要本地作了提交，就可以通过命令:git push origin master把本地master分支的最新修改推送至GitHub

2.六麦环形阵列：
模块利用麦克风阵列的空域滤波特性（不仅利用了声音的时间频率特性，还利用了空间特性）,通过对唤醒人的角度定位,形成定向拾音波束,并对波束以外的噪声进行抑制,以保证较高的录音质量。
六个拾音波束，各自对应60°范围　阵列算法通过增强波束范围内的声音，削弱波束外的声音，以增强　录音信噪比；
５ｍ远场拾音，声源定位，多种拾音模式（唤醒、定向、全向），中英文唤醒词，唤醒效果检测（评分、调参）
附：唤醒拾音模式即每次说话前需对麦克风进行唤醒,之后麦克风才可以拾取声源所在方向上的声音;定向拾音模式即开发者可随时指定特定的麦克风进行拾音,使设备达到跟踪声源进行拾音的效果,主要适用于机器人等场景;全向拾音模式即麦克风阵列无需唤醒,可拾取任意方向上声源的声音,可适用于通话、会议等场景

科大讯飞技术文档：硬件连接实物图、SecureCRT工具（命令设置）
声纹识别：是一项提取说话人声音特征和说话内容信息，自动核验说话人身份的技术

3.决策树算法：
决策树：从根节点开始一步步走到子节点（决策）
所有的数据最终都会落到叶子节点，既可以做分类也可以做回归

树的组成:
根节点：第一个选择点
非叶子节点与分支:中间过程
叶子节点：最终的决策结果

增加节点相当于在数据中切一刀

决策树的训练与测试:
训练阶段：从给定的训练集构造出一颗树（从根节点开始选择特征，如何进行特征切分）
测试阶段：根据构造出的树模型从上到下走一遍

如何切分特征（选择节点）:衡量标准－熵 选择信息增益最大的作为根节点，依次
信息增益（特征X使得类Y不确定性减少的程度）问题（ID)增益为０
信息增益率:信息增益/自身熵值（解决ID问题，考虑自身熵)
CART：使用GINI系数当做衡量标准　GINI系数：1-概率平方的累加

熵：随机变量不确定性的度量　公式：H(x)=-累加p*logp

决策树的构造实例：

决策树剪枝策略：
预剪枝（边建立边剪枝，限制深度-特征数、叶子节点个数、信息增益，常用）
后剪枝（叶子节点越多，损失越大）
第５节完

2018.3.4　周日　晴

ubuntu无自带flash插件
ubuntu16.04如何通过Firefox安装Flash插件(https://jingyan.baidu.com/article/2fb0ba40a7832600f2ec5f80.html)

te：Training Epochs，训练迭代次数
tf.truncated_normal()，变量初始化为标准截断正态分布的随机数
tf.zeros()，变量初始化为0　　　　
display_step = 1　每多少次迭代显示一次损失

# tensor `a` is [1.8, 2.2], dtype=tf.float  
tf.cast(a, tf.int32) ==> [1, 2]  # dtype=tf.int32  类型转换函数
duce_mean(x) ==> 2.5 #如果不指定第二个参数，那么就在所有的元素中取平均值
tf.reduce_mean(x, 0) ==> [2.,  3.] #指定第二个参数为0，则第一维的元素取平均值，即每一列求平均值

tensorflow中有一类在tensor的某一维度上求值的函数。如：
求最大值tf.reduce_max(input_tensor, reduction_indices=None, keep_dims=False, name=None)
求平均值tf.reduce_mean(input_tensor, reduction_indices=None, keep_dims=False, name=None)
参数1--input_tensor:待求值的tensor。
参数2--reduction_indices:在哪一维上求解。　参数（3）（4）可忽略
tf.argmax的使用（http://blog.csdn.net/uestc_c2_403/article/details/72232807）

读DeepSpeech＆DeepSpeech２论文（论文、译、笔记 在Documents/DeepSpeech论文中）

2018.3.5 周一　晴

读DeepSpeech＆DeepSpeech２论文（论文、译、笔记 在Documents/DeepSpeech论文中）

softmax函数的特点和作用是什么（https://www.zhihu.com/question/23765351杨思达ok忆臻详解）
元素的softmax值为:该元素的指数，与所有元素指数和的比值 把值映射到0到1上，可认为是概率
loss定义为交叉熵：-㏒(softmax)　概率越大，损失越小
最后结果的形式非常的简单，只要将算出来的概率的向量对应的真正结果的那一维减1，就可以了
科大讯飞的语音听写　研究
晚上高级程序设计课　基本：熟悉的教材　敲代码正比变成能力　交流

2018.3.6　周二　晴

ubuntu 16.04 VSCode 配置C++开发环境 （http://blog.csdn.net/u011258217/article/details/78693564）
ubuntu16.04版本的名称xenial
添加更改源：system settings->software&updates
PPA源（Personal Package Archives 个人软件包文档）
https://www.cnblogs.com/EasonJim/p/7119331.html＆https://imcn.me/ppa

3.6&3.7打标签

2018.3.8　周四　晴

编辑makefile文件：insert->进入编辑模式->esc(退出编辑)->shift:->wq
linux makefile教程（http://blog.csdn.net/liang13664759/article/details/1771246/）
makefile都成为了一种在工程方面的编译方法，关系到了整个工程的编译规则
makefile带来的好处就是——“自动化编译”　无论是C、C++、还是pas，首先要把源文件编译成中间代码文件，在Windows下也就是 .obj 文件，UNIX下是 .o 文件，即 Object File，这个动作叫做编译（compile）。然后再把大量的Object File合成执行文件，这个动作叫作链接（link）　

配置讯飞听写　失败(source 64bit_make.sh报错)
设置当前用户的环境变量：sudo gedit ~/.bashrc 打开.bashrc文件　末尾添加路径（eg:export PATH=/opt/EmbedSky/4.3.3/bin:$PATH 其中/opt/EmbedSky/4.3.3/bin为你自己需要设置的环境变量路径）使其立即生效，在终端执行：source ~/.bashrc
ubuntu16.04配置环境变量（https://www.cnblogs.com/imayi/p/6082122.html＆http://blog.csdn.net/baidu_34045013/article/details/78237825＆http://blog.csdn.net/Bleachswh/article/details/51334661）
Linux下profile和bashrc四种的区别（https://zhidao.baidu.com/question/556207103012196652.html:
全局vs当前用户　.bashrc vs .profile
译完DeepSpeech论文　（论文、译、笔记 在Documents/DeepSpeech论文中）

2018.3.9 周五　晴

Ubuntu解压缩zip,tar,tar.gz,tar.bz2:http://www.linuxidc.com/Linux/2012-08/68122.htm
Anaconda+用conda创建python虚拟环境:https://www.cnblogs.com/swje/p/7642929.html
用conda创建python虚拟环境(简明版):http://blog.csdn.net/lyy14011305/article/details/59500819
安装labelImg失败（虚拟环境中也尝试了），qt报错
Shift+PrintScreenSysRq 这两个按键组合截图
返回上一级目录　cd ..
返回上两级目录　cd ../..   返回上次操作的目录　cd ~
linux中mv命令使用详解https://www.cnblogs.com/piaozhe116/p/6084214.html
mv [选项] 源文件或目录 目标文件或目录
创建软连接：ln –s 源文件 目标文件　只会在选定的位置上生成一个文件的镜像，不会占用磁盘空间，类似与windows的快捷方式　硬链接ln源文件目标文件，没有参数-s， 会在选定的位置上生成一个和源文件大小相同的文件，无论是软链接还是硬链接，文件都保持同步变化
Shift+PrintScreenSysRq 这两个按键组合截图

2018.3.10 周六　晴雪
上午听答辩，中午被阿田大虾治愈了，下午睡觉＆健身房，晚上打卡休息。

2018.3.11 周日　晴

deepspeech录音　识别demo
end-to-end神经网络：
端到端指的是输入是原始数据，输出是最后的结果；端到端网络，特征可以自己去学习，所以特征提取这一步也就融入到算法当中.
特征提取的好坏非常关键，特征需要足够的经验去设计，这在数据量越来越大的情况下也越来越困难
端到端的学习思路非常简单：音频->学习算法->转录结果
传统的语音识别需要把语音转化为语音特征向量，然后把这组向量通过机器学习，分类到各种音节上（根据语模型），然后通过音节，还原出最大概率的语音原本要表达的单词。
传统的语音识别：语音->特征提取模块（把语音变成向量）->解码器（声学模型-识别语音向量、发音词典-包含系统能处理的词汇及发音—提供了声学模型与语言模型的联系、语言模型-对系统针对的语言进行建模；解码器整体任务是对输入的信号，根据声学、语言模型及词典，寻找能够以最大概率输出信号的词串）->结果
传统的语音识别中的语音模型和语言模型是分别训练的，缺点是不一定能够从总体上提高识别率
http://www.360doc.com/content/16/1229/22/32626470_618762237.shtml

2018.3.12 周一　阴
文语对齐（Text-Speech Alignment）是以语音识别系统为基础，对语音和文本在时间上进行强制对齐的过程
（无标注的中文长篇幅语音文语对齐的研究http://cdmd.cnki.com.cn/Article/CDMD-10423-1014203845.htm）
高级程序设计之数据结构：数据元素的组织形式和相互之间的关系
数据的逻辑结构：线性结构、树结构、图结构（前驱数据元素和后继数据元素决定）
数据的存储结构：顺序存储结构、指针、链式存储结构（逻辑上相邻物理上不一定相邻）
数据的操作：主要讨论操作的具体实现算法
数据结构主要讨论线性表、堆栈、队列、串、数组、二叉树、图等典型常用的数据结构，并主要从以上三方面分析。
抽象数据类型（大型软件最基本的模块）
算法及其时间复杂度（时间效率）
算法的执行时间：事后统计法（考察重点）＆事前分析方法
算法的时间效率是算法处理的数据个数n的函数
汉诺塔问题，２的次方形式递增
冒泡排序时间复杂度n平方，快速排序ｎ*lb(切刀)

科大讯飞语音听写sdk下载配置，完成demo；但语音识别只能部分词；

2018.3.13　周二　阴
陪室友去医院＆健身房＆晚上gitlfs 程序bug

2018.3.14 周三　小雨
Git LFS 入门指南　www.oschina.net/translate/getting-started-with-git-lfs-tutorial
Git LFS 支持大文件存储　http://blog.csdn.net/aoshilang2249/article/details/71248896
重新 git lfs clone deepspeech比直接clone　zip解压要大很多，为什么？
重装格式错误仍然存在。。
并且由于安装了tensorflow1.6　出现错误libcudart.so.9.0: cannot open shared object file: No such file or directory　由于cuda8.0只支持tensorflow1.4及以下版本
　tensorflow暂未兼容cuda9.0 但卸载tensorflow-gpu-1.6版本后仍然报同样错误。。
晚上健身房＆高级程序设计：
数组：数据类型相同地址连续　　Ｃ语言行主序，matlab列主序
地址都是一维的　由首地址定位整个数组
静态数组　动态数组（申请一维二维动态数组方法）
相同时间复杂度　运算时间差异原因（yix方式运算速度快）
高速缓存cache的不命中率低，cache中数据利用率高
（Cache块大小对命中率的影响https://wenku.baidu.com/view/ef90cb4eed630b1c59eeb5da.html）

一天都在写bug。。。刚发现今天是白色情人节

2018.3.15 周四　晴
录音测试，问题是只能听写录好的音频，不能实时听写；
读论文　
理解dropout(指在深度学习网络的训练过程中，对于神经网络单元，按照一定的概率将其暂时从网络中丢弃,注意是暂时，对于随机梯度下降来说，由于是随机丢弃，故而每一个mini-batch都在训练不同的网络.防止过拟合)http://blog.csdn.net/stdcoutzyx/article/details/49022443
RNN训练设置部分：五层网络
第四层双向循环层h（f）必须从t = 1到t = T（i）顺序计算第i个话语，而单位h（b）必须从t = T（i）到t = 1　　　　正确标记的数据叫做ground truth
CTC的训练准则是基于序列（比如语音识别的一整句话）的，比如最大化p(z|x)，序列化的概率求解比较复杂，因为一个输出序列可以对应很多的路径，所有引入前后向算法来简化计算。CTC训练是真正的序列训练，优化整个序列的损失，而不是优化单点的损失
百度贾磊LSTM+CTC详解　http://lib.csdn.net/article/deeplearning/47821
mini-batch是将训练集分组，分组之后，分别对每组求梯度，然后更新参数
随着每个GPU内的小批量缩小，大多数操作都会受到内存带宽的限制
https://baijiahao.baidu.com/s?id=1578230866597574335&wfr=spider&for=pc

3.16 星期五　晴

支持向量机SVM:
决策边界：Large Margin 决策边界越胖越好　选出离雷区最远的
距离与数据的定义
决策方程
fprintf()、sprintf()、printf()、fwrite()函数的用法与区别
http://blog.csdn.net/ltstud/article/details/76436757
ftell函数用于得到文件位置指针当前位置相对于文件首的偏移字节数（获取文件读写指针的当前位置）
http://blog.csdn.net/stpeace/article/details/8245335
fseek()用来移动文件流的读写位置

3.21 星期三　晴
16.04　xenial
14.04　trust

